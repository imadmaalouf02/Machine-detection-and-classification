{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= YOLO('bestN.pt') \n",
    "class_names = model.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2\n",
      "0.16.2+cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torchvision\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Détection en utilisant des vidéos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x800 1 fraiseuse, 1139.1ms\n",
      "Speed: 32.1ms preprocess, 1139.1ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 fraiseuse, 837.3ms\n",
      "Speed: 43.3ms preprocess, 837.3ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 fraiseuse, 409.1ms\n",
      "Speed: 12.0ms preprocess, 409.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 fraiseuse, 391.9ms\n",
      "Speed: 13.2ms preprocess, 391.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 fraiseuse, 625.2ms\n",
      "Speed: 10.9ms preprocess, 625.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 fraiseuse, 588.7ms\n",
      "Speed: 17.0ms preprocess, 588.7ms inference, 11.6ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 fraiseuse, 679.7ms\n",
      "Speed: 27.3ms preprocess, 679.7ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 fraiseuse, 693.6ms\n",
      "Speed: 37.9ms preprocess, 693.6ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 fraiseuse, 698.8ms\n",
      "Speed: 18.3ms preprocess, 698.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 fraiseuse, 447.8ms\n",
      "Speed: 12.0ms preprocess, 447.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 fraiseuse, 398.2ms\n",
      "Speed: 18.0ms preprocess, 398.2ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 fraiseuse, 371.2ms\n",
      "Speed: 10.3ms preprocess, 371.2ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 fraiseuse, 575.5ms\n",
      "Speed: 35.9ms preprocess, 575.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 fraiseuse, 493.2ms\n",
      "Speed: 40.9ms preprocess, 493.2ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 fraiseuse, 360.1ms\n",
      "Speed: 18.0ms preprocess, 360.1ms inference, 3.9ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 fraiseuse, 359.4ms\n",
      "Speed: 10.0ms preprocess, 359.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 800)\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('fr.mp4')\n",
    "while cap.isOpened():\n",
    "    ret,frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    detection_result =model(frame)\n",
    "    for r in detection_result:\n",
    "        boxes=r.boxes\n",
    "        for box in boxes:\n",
    "            if box:\n",
    "                x1,y1,x2,y2 = box.xyxy[0]\n",
    "                x1,y1,x2,y2 = int(x1),int(y1),int(x2),int(y2)\n",
    "                frame = cv2.rectangle(frame,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "                cv2.putText(frame,class_names[int(box.cls)]+\" \"+str(round(float(box.conf),2)),(x1+20,y1+20),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),2,cv2.LINE_AA)\n",
    "    cv2.imshow('frame',frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 800x480 1 perceuse, 447.9ms\n",
      "Speed: 19.6ms preprocess, 447.9ms inference, 1.4ms postprocess per image at shape (1, 3, 800, 480)\n",
      "\n",
      "0: 800x480 1 perceuse, 496.5ms\n",
      "Speed: 39.9ms preprocess, 496.5ms inference, 2.1ms postprocess per image at shape (1, 3, 800, 480)\n",
      "\n",
      "0: 800x480 1 perceuse, 402.1ms\n",
      "Speed: 13.8ms preprocess, 402.1ms inference, 6.0ms postprocess per image at shape (1, 3, 800, 480)\n",
      "\n",
      "0: 800x480 1 perceuse, 478.0ms\n",
      "Speed: 21.9ms preprocess, 478.0ms inference, 3.0ms postprocess per image at shape (1, 3, 800, 480)\n",
      "\n",
      "0: 800x480 1 perceuse, 412.0ms\n",
      "Speed: 18.0ms preprocess, 412.0ms inference, 2.0ms postprocess per image at shape (1, 3, 800, 480)\n",
      "\n",
      "0: 800x480 1 perceuse, 387.5ms\n",
      "Speed: 14.0ms preprocess, 387.5ms inference, 2.3ms postprocess per image at shape (1, 3, 800, 480)\n",
      "\n",
      "0: 800x480 1 perceuse, 395.6ms\n",
      "Speed: 11.0ms preprocess, 395.6ms inference, 2.0ms postprocess per image at shape (1, 3, 800, 480)\n",
      "\n",
      "0: 800x480 1 perceuse, 608.7ms\n",
      "Speed: 35.0ms preprocess, 608.7ms inference, 4.0ms postprocess per image at shape (1, 3, 800, 480)\n",
      "\n",
      "0: 800x480 1 perceuse, 528.2ms\n",
      "Speed: 29.9ms preprocess, 528.2ms inference, 2.7ms postprocess per image at shape (1, 3, 800, 480)\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('per.mp4')\n",
    "while cap.isOpened():\n",
    "    ret,frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    detection_result =model(frame)\n",
    "    for r in detection_result:\n",
    "        boxes=r.boxes\n",
    "        for box in boxes:\n",
    "            if box:\n",
    "                x1,y1,x2,y2 = box.xyxy[0]\n",
    "                x1,y1,x2,y2 = int(x1),int(y1),int(x2),int(y2)\n",
    "                frame = cv2.rectangle(frame,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "                cv2.putText(frame,class_names[int(box.cls)]+\" \"+str(round(float(box.conf),2)),(x1+20,y1+20),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),2,cv2.LINE_AA)\n",
    "    cv2.imshow('frame',frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x800 1 tour parallele, 602.0ms\n",
      "Speed: 14.0ms preprocess, 602.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 tour parallele, 547.0ms\n",
      "Speed: 29.9ms preprocess, 547.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 tour parallele, 277.5ms\n",
      "Speed: 10.3ms preprocess, 277.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 tour parallele, 285.8ms\n",
      "Speed: 9.0ms preprocess, 285.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 tour parallele, 328.4ms\n",
      "Speed: 8.0ms preprocess, 328.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 tour parallele, 263.5ms\n",
      "Speed: 11.3ms preprocess, 263.5ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 tour parallele, 295.0ms\n",
      "Speed: 13.2ms preprocess, 295.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 tour parallele, 322.3ms\n",
      "Speed: 8.5ms preprocess, 322.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 tour parallele, 322.1ms\n",
      "Speed: 13.0ms preprocess, 322.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 tour parallele, 311.2ms\n",
      "Speed: 20.0ms preprocess, 311.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 tour parallele, 302.0ms\n",
      "Speed: 8.2ms preprocess, 302.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 tour parallele, 379.2ms\n",
      "Speed: 22.9ms preprocess, 379.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 tour parallele, 373.2ms\n",
      "Speed: 12.0ms preprocess, 373.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 tour parallele, 339.2ms\n",
      "Speed: 13.0ms preprocess, 339.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 tour parallele, 313.5ms\n",
      "Speed: 14.2ms preprocess, 313.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 tour parallele, 550.2ms\n",
      "Speed: 16.1ms preprocess, 550.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 tour parallele, 591.7ms\n",
      "Speed: 20.0ms preprocess, 591.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 tour parallele, 322.0ms\n",
      "Speed: 15.5ms preprocess, 322.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 tour parallele, 274.8ms\n",
      "Speed: 10.0ms preprocess, 274.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 tour parallele, 284.7ms\n",
      "Speed: 8.0ms preprocess, 284.7ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 tour parallele, 291.9ms\n",
      "Speed: 9.9ms preprocess, 291.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 tour parallele, 278.5ms\n",
      "Speed: 8.0ms preprocess, 278.5ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 tour parallele, 260.7ms\n",
      "Speed: 9.0ms preprocess, 260.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 tour parallele, 253.9ms\n",
      "Speed: 8.0ms preprocess, 253.9ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 tour parallele, 297.2ms\n",
      "Speed: 10.0ms preprocess, 297.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 tour parallele, 271.8ms\n",
      "Speed: 9.8ms preprocess, 271.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 tour parallele, 282.9ms\n",
      "Speed: 7.0ms preprocess, 282.9ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 tour parallele, 258.9ms\n",
      "Speed: 9.0ms preprocess, 258.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 tour parallele, 258.3ms\n",
      "Speed: 8.0ms preprocess, 258.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 tour parallele, 272.0ms\n",
      "Speed: 10.8ms preprocess, 272.0ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 tour parallele, 265.2ms\n",
      "Speed: 11.0ms preprocess, 265.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 tour parallele, 261.4ms\n",
      "Speed: 12.6ms preprocess, 261.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 tour parallele, 262.6ms\n",
      "Speed: 10.0ms preprocess, 262.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 tour parallele, 270.5ms\n",
      "Speed: 11.0ms preprocess, 270.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 tour parallele, 272.3ms\n",
      "Speed: 10.0ms preprocess, 272.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 tour parallele, 239.0ms\n",
      "Speed: 11.0ms preprocess, 239.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 tour parallele, 249.5ms\n",
      "Speed: 9.0ms preprocess, 249.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 tour parallele, 268.5ms\n",
      "Speed: 7.6ms preprocess, 268.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 tour parallele, 251.6ms\n",
      "Speed: 9.2ms preprocess, 251.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 tour parallele, 256.4ms\n",
      "Speed: 10.2ms preprocess, 256.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 tour parallele, 264.3ms\n",
      "Speed: 12.2ms preprocess, 264.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 tour parallele, 253.4ms\n",
      "Speed: 10.1ms preprocess, 253.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 tour parallele, 244.4ms\n",
      "Speed: 9.1ms preprocess, 244.4ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 tour parallele, 260.7ms\n",
      "Speed: 10.0ms preprocess, 260.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 tour parallele, 279.8ms\n",
      "Speed: 8.4ms preprocess, 279.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 800)\n",
      "\n",
      "0: 480x800 1 tour parallele, 288.8ms\n",
      "Speed: 10.0ms preprocess, 288.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 800)\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('vid.mp4')\n",
    "while cap.isOpened():\n",
    "    ret,frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    detection_result =model(frame)\n",
    "    for r in detection_result:\n",
    "        boxes=r.boxes\n",
    "        for box in boxes:\n",
    "            if box:\n",
    "                x1,y1,x2,y2 = box.xyxy[0]\n",
    "                x1,y1,x2,y2 = int(x1),int(y1),int(x2),int(y2)\n",
    "                frame = cv2.rectangle(frame,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "                cv2.putText(frame,class_names[int(box.cls)]+\" \"+str(round(float(box.conf),2)),(x1+20,y1+20),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),2,cv2.LINE_AA)\n",
    "    cv2.imshow('frame',frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Détection en utilisant la caméra du système."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 608x800 (no detections), 660.4ms\n",
      "Speed: 15.0ms preprocess, 660.4ms inference, 2.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 637.2ms\n",
      "Speed: 26.9ms preprocess, 637.2ms inference, 2.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 460.5ms\n",
      "Speed: 13.4ms preprocess, 460.5ms inference, 2.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 tour parallele, 381.1ms\n",
      "Speed: 11.0ms preprocess, 381.1ms inference, 2.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 369.0ms\n",
      "Speed: 15.3ms preprocess, 369.0ms inference, 2.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 352.4ms\n",
      "Speed: 10.8ms preprocess, 352.4ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 369.5ms\n",
      "Speed: 8.5ms preprocess, 369.5ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 364.3ms\n",
      "Speed: 8.0ms preprocess, 364.3ms inference, 2.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 353.5ms\n",
      "Speed: 11.6ms preprocess, 353.5ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 353.0ms\n",
      "Speed: 10.2ms preprocess, 353.0ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 328.9ms\n",
      "Speed: 10.1ms preprocess, 328.9ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 357.2ms\n",
      "Speed: 13.0ms preprocess, 357.2ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 343.4ms\n",
      "Speed: 12.0ms preprocess, 343.4ms inference, 2.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 397.8ms\n",
      "Speed: 12.0ms preprocess, 397.8ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 401.6ms\n",
      "Speed: 14.4ms preprocess, 401.6ms inference, 1.1ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 375.0ms\n",
      "Speed: 13.6ms preprocess, 375.0ms inference, 0.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 373.3ms\n",
      "Speed: 16.0ms preprocess, 373.3ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 (no detections), 378.4ms\n",
      "Speed: 12.0ms preprocess, 378.4ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 800)\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret,frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    detection_result =model(frame)\n",
    "    for r in detection_result:\n",
    "        boxes=r.boxes\n",
    "        for box in boxes:\n",
    "            if box:\n",
    "                x1,y1,x2,y2 = box.xyxy[0]\n",
    "                x1,y1,x2,y2 = int(x1),int(y1),int(x2),int(y2)\n",
    "                frame = cv2.rectangle(frame,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "                cv2.putText(frame,class_names[int(box.cls)]+\" \"+str(round(float(box.conf),2)),(x1+20,y1+20),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),2,cv2.LINE_AA)\n",
    "    cv2.imshow('frame',frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Détection en utilisant de nouvelles images qui ne sont pas apparues dans nos data, que ce soit par atelier ou sur le web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 416x800 1 fraiseuse, 506.2ms\n",
      "Speed: 13.0ms preprocess, 506.2ms inference, 3.0ms postprocess per image at shape (1, 3, 416, 800)\n",
      "fraiseuse\n"
     ]
    }
   ],
   "source": [
    "img=cv2.imread('fr3.jpg')\n",
    "detection_result = model(img)\n",
    "for r in detection_result:\n",
    "    boxes=r.boxes\n",
    "    for box in boxes:\n",
    "        if box:\n",
    "            x1,y1,x2,y2 = box.xyxy[0]\n",
    "            x1,y1,x2,y2 = int(x1),int(y1),int(x2),int(y2)\n",
    "            img = cv2.rectangle(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "            print(class_names[int(box.cls)])\n",
    "            cv2.putText(img,class_names[int(box.cls)]+\" \"+str(round(float(box.conf),2)),(x1+20,y1+20),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),2,cv2.LINE_AA)\n",
    "            break\n",
    "cv2.imshow('img',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 640x800 1 tour parallele, 365.5ms\n",
      "Speed: 13.0ms preprocess, 365.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 800)\n",
      "tour parallele\n"
     ]
    }
   ],
   "source": [
    "img=cv2.imread('tour.jpg')\n",
    "detection_result = model(img)\n",
    "for r in detection_result:\n",
    "    boxes=r.boxes\n",
    "    for box in boxes:\n",
    "        if box:\n",
    "            x1,y1,x2,y2 = box.xyxy[0]\n",
    "            x1,y1,x2,y2 = int(x1),int(y1),int(x2),int(y2)\n",
    "            img = cv2.rectangle(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "            print(class_names[int(box.cls)])\n",
    "            cv2.putText(img,class_names[int(box.cls)]+\" \"+str(round(float(box.conf),2)),(x1+20,y1+20),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),2,cv2.LINE_AA)\n",
    "            break\n",
    "cv2.imshow('img',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 800x608 1 perceuse, 460.9ms\n",
      "Speed: 14.0ms preprocess, 460.9ms inference, 1.0ms postprocess per image at shape (1, 3, 800, 608)\n",
      "perceuse\n"
     ]
    }
   ],
   "source": [
    "img=cv2.imread('percc.jpg')\n",
    "detection_result = model(img)\n",
    "for r in detection_result:\n",
    "    boxes=r.boxes\n",
    "    for box in boxes:\n",
    "        if box:\n",
    "            x1,y1,x2,y2 = box.xyxy[0]\n",
    "            x1,y1,x2,y2 = int(x1),int(y1),int(x2),int(y2)\n",
    "            img = cv2.rectangle(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "            print(class_names[int(box.cls)])\n",
    "            cv2.putText(img,class_names[int(box.cls)]+\" \"+str(round(float(box.conf),2)),(x1+20,y1+20),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),2,cv2.LINE_AA)\n",
    "            break\n",
    "cv2.imshow('img',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 800x800 1 perceuse, 837.2ms\n",
      "Speed: 30.3ms preprocess, 837.2ms inference, 3.0ms postprocess per image at shape (1, 3, 800, 800)\n",
      "perceuse\n"
     ]
    }
   ],
   "source": [
    "img=cv2.imread('test4.webp')\n",
    "#img=cv2.imread('test3.webp')\n",
    "detection_result = model(img)\n",
    "object_counter = 0\n",
    "for r in detection_result:\n",
    "    boxes=r.boxes\n",
    "    for box in boxes:\n",
    "        if box:\n",
    "            x1,y1,x2,y2 = box.xyxy[0]\n",
    "            x1,y1,x2,y2 = int(x1),int(y1),int(x2),int(y2)\n",
    "            img = cv2.rectangle(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "            print(class_names[int(box.cls)])\n",
    "            cv2.putText(img,class_names[int(box.cls)]+\" \"+str(round(float(box.conf),2)),(x1+20,y1+20),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),2,cv2.LINE_AA)\n",
    "            object_counter += 1\n",
    "            if object_counter > 8:\n",
    "                break\n",
    "cv2.imshow('img',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Détection de plusieurs machines de la même image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x800 1 tour parallele, 638.1ms\n",
      "Speed: 32.9ms preprocess, 638.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 800)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('deux.jpg')\n",
    "detection_result = model(img)\n",
    "\n",
    "# Initialize a counter for limiting the number of detected objects\n",
    "object_counter = 0\n",
    "\n",
    "for r in detection_result:\n",
    "    boxes = r.boxes\n",
    "    for box in boxes:\n",
    "        if box:\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "            # Draw rectangle and label\n",
    "            img = cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            label = f\"{class_names[int(box.cls)]} {round(float(box.conf), 2)}\"\n",
    "            cv2.putText(img, label, (x1 + 20, y1 + 20), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "            # Increment the object counter\n",
    "            object_counter += 1\n",
    "\n",
    "            # Break if  5 objects are detected\n",
    "            if object_counter > 5:\n",
    "                break\n",
    "\n",
    "# Display the modified image\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Factory_Safety",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
